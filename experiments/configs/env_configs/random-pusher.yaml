# Experiment parameters
training:

  # Environment parameters
  name: RandomMBPusherEnv
  max_steps: 150
  action_cost: 0.1

  # Training parameters
  train_episodes: 800
  test_episodes: 20

  # Meta-training parameters
  num_train_env_instances: 20
  num_test_env_instances: 5
  num_test_episodes_per_env: 25


# Agent parameters
pacoh:

  # Data collection and exploration parameters
  collect_meta_data: False
  pacoh_training_model_kind: "BayesianNN"
  exploration: "greedy"
  pacoh_optimistic_evaluation: False
  beta: 1.5

  # Model parameters
  model_kind: "BayesianNN"
  model_layers: [ 200, 200, 200, 200 ]
  model_non_linearity: "ReLU"
  model_opt_lr: 0.001
  model_opt_weight_decay: 0.0001
  model_learn_num_iter: 2000
  model_learn_batch_size: 100
  model_include_aleatoric_uncertainty: False
  model_prediction_strategy: "moment_matching" # Important, choices: ["moment_matching", "sample_multiple_head"]

  # Critic parameters
  value_function_layers: [400, 400]
  value_function_non_linearity: "Swish"

  # Policy parameters
  gamma: 0.99
  policy_layers: [400, 400]
  policy_non_linearity: "Swish"
  ppo_opt_lr: 0.0005
  policy_tau: 0.005
  policy_opt_gradient_steps: 40000
  policy_train_freq: 1
  policy_grad_steps: 1
  sac_use_sde: False
  sim_num_steps: 42

  # PACOH Parameters
  pacoh_num_iter_meta_train: 100000
  pacoh_num_iter_eval_train: 25
  pacoh_num_hyper_posterior_particles: 3
  pacoh_n_samples_per_prior: 3
  pacoh_num_posterior_particles: 3
  pacoh_likelihood_std: 0.1

  # Parallel Rollout Parameters
  parallel_episodes_per_env: 1
  num_episodes_per_rollout: 1

mbpo:

  # Model parameters
  model_kind: "BayesianNN"
  model_layers: [ 200, 200, 200, 200 ]
  model_non_linearity: "ReLU"
  model_opt_lr: 0.001
  model_opt_weight_decay: 0.0001
  model_learn_num_iter: 2000
  model_learn_batch_size: 100
  model_include_aleatoric_uncertainty: False
  model_prediction_strategy: "moment_matching" # Important, choices: ["moment_matching", "sample_multiple_head"]

  # Critic parameters
  value_function_layers: [400, 400]
  value_function_non_linearity: "Swish"

  # Policy parameters
  gamma: 0.99
  policy_layers: [400, 400]
  policy_non_linearity: "Swish"
  ppo_opt_lr: 0.0005
  policy_tau: 0.005
  policy_opt_gradient_steps: 40000
  policy_train_freq: 1
  policy_grad_steps: 1
  sac_use_sde: False
  sac_ent_coef: "auto"
  sim_num_steps: 42
