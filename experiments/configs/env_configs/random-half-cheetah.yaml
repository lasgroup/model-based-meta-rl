# Experiment parameters
training:

  # Environment parameters
  name: RandomMBHalfCheetahEnv
  max_steps: 1000
  action_cost: 0.1

  # Training parameters
  train_episodes: 1200
  test_episodes: 20

  # Meta-training parameters
  num_train_env_instances: 20
  num_test_env_instances: 5
  num_test_episodes_per_env: 25

  # Data collection and exploration parameters
  collect_meta_data: False
  exploration: "greedy"
  beta: 1.5
  pacoh_training_model_kind: "BayesianNN"
  pacoh_optimistic_evaluation: False

# Model Parameters
model:

  model_kind: "BayesianNN"
  model_layers: [400, 400, 400, 400]
  model_non_linearity: "ReLU"
  model_opt_lr: 0.001
  model_opt_weight_decay: 0.00005
  model_learn_num_iter: 2000
  model_learn_batch_size: 200
  model_include_aleatoric_uncertainty: False
  model_prediction_strategy: "moment_matching" # Important, choices: ["moment_matching", "sample_multiple_head"]

# SAC Parameters
policy:

  # Critic parameters
  value_function_layers: [400, 400]
  value_function_non_linearity: "Swish"

  # Policy parameters
  gamma: 0.99
  policy_layers: [400, 400]
  policy_non_linearity: "Swish"
  ppo_opt_lr: 0.0005
  policy_tau: 0.005
  policy_opt_gradient_steps: 40000
  policy_train_freq: 10
  policy_grad_steps: 1
  sac_use_sde: False
  sac_ent_coef: "auto"
  sim_num_steps: 32

# MBPO Parameters
mbpo: {}

# PACOH Parameters
pacoh:

  pacoh_num_iter_meta_train: 100000
  pacoh_num_iter_eval_train: 25
  pacoh_num_hyper_posterior_particles: 3
  pacoh_n_samples_per_prior: 3
  pacoh_num_posterior_particles: 3
  pacoh_likelihood_std: 0.1

  # Parallel Rollout Parameters
  parallel_episodes_per_env: 1
  num_episodes_per_rollout: 1

#GrBAL Parameters
grbal:

  model_kind: "ProbabilisticNN"
  model_opt_weight_decay: 0.0001
  model_learn_batch_size: 16

  # Parallel Rollout Parameters
  num_episodes_per_rollout: 1
  grbal_num_parallel_agents: 5

  # GrBAL Parameters
  grbal_past_segment_len: 32
  grbal_future_segment_len: 32
  grbal_inner_lr: 0.003
  grbal_num_iter_meta_train: 20000
